First of all, we would like to thank all the reviewers and the editor for reading the paper and providing constructive comments that have certainly improved the paper. We hope that the changes we have made to the manuscript have taken away any concerns the reviewers had. The most important change is that, as per the suggestions of one of the reviewers, we have included a proof of improvement for the multivariate case for a slight adaptation of the ICLS procedure. We have updated the rest of the manuscript accordingly to reflect the addition of this important result. In particular we updated the experiments section and discussion to include results for both this adapted procedure and the procedure used in theorem 2.


We will now cover the specific concerns brought forth by the reviewers and the subsequent changes to the manuscript one by one.


Editor’s comments: 
We very much agree with your comments that the results could be generalized further. We have studied this question for a while, especially in the context of likelihood based models such as linear discriminant analysis, quadratic discriminant analysis and the likes, where similar results can be attained. As per your suggestion, we have extended the discussion in section 6 to discuss these issues. However, we feel that a thorough introduction of these results  is beyond the scope of this paper. The main point we want to get across is the interesting observation that for some models we can do robust semi-supervised learning without the traditional assumptions considered to be required for semi-supervised learning. It is certainly important to emphasize least squares is just one, theoretically interesting, example of this, which we hope we have now done.


Regarding the lack of assumptions, it is indeed generally true (as Shalev-Shwartz and Ben-David argue), that the hypothesis space is a very important part of the assumptions underlying any classifier. We have tried to emphasize the point that in the context of deriving a semi-supervised version of a supervised classifier, these assumptions that are already made by the choice of supervised classifier may already be enough to leverage them to construct a semi-supervised variant. The additional constraint that we introduce on the hypothesis space, seems to only rely on the additional assumption that the loss of the supervised classifier would improve if we add more labeled data. This seems very reasonable for most classifiers. If we can not hope to improve performance using labeled data, what hope is there using unlabeled data? We have improved section 6 to clarify this point.

Reviewer #1: 
We have included a short discussion of how the results presented in "Unlabeled data: Now it helps, now it doesn’t” by  Singh, Nowark and Zhu relate to our work. While the goal of their work is similar in the way of exploring the limits of semi-supervised learning, their main contribution is stating what we may be able to prove once we make a clustering assumption, while one of the main insights offered by our work is that there are cases where we can do without this additional assumption, and rely only on the choice of the supervised classifier alone. We do very much agree with their observation that the benefits of semi-supervised learning may be more fruitfully studied in a finite sample scenario.

Reviewer #2: 
We would like to thank the reviewer for having an in depth look at the method, to identify a possible contradiction in the method and the results. We think, however, that the argument that the constraint is redundant is based on a misunderstanding of the supervised model, which we have tried to clarify in the new manuscript. The problem lies in the statement that "Then, \beta^* will give a prediction for the unlabeled data, denoted by y_u, which is of cause a possible label assignment for the unlabeled data.” This is not true for the least squares classifier, since its output is unbounded. In essence, the output of x^{\top} \beta^* can be larger than 1 or smaller than 0. Since we know the labels should be 0 or 1, or in the relaxed setting [0,1], we cannot assign labels that will give 0 loss on (X_u, y_u). Take for instance the very simple setting where we have two labeled objects in 1d, one point at x=-1 labeled 0 and one at x=+1 labeled 1. The supervised parameter estimate would give: y=a+b*x=0.5+0.5*x. Now suppose we have on unlabeled object at x=2. There is no labeling possible such that we will again find the parameters a=0.5, b=0.5. In other words, this \beta^* will not be in the constrained set. We hope this issue is now clearer in the revised text of sections 3 and 4.


Thank you for pointing out the typos, which we have corrected in the new version of the manuscript.


Reviewer #3:
Thank you very much for the thorough review and thoughtful comments. We will address them one by one.
1. Although the squared loss may not be as popular as some often techniques and may be odd as a classification loss it has surprisingly solid performance in many practical settings, see for example the works by Poggio, Rasmussen and others referenced in the manuscript. In other words, in the supervised setting it leads to useful classifiers for many problems. Regardless, the goal of our work is to show there is a classifier (in this case the least squares classifier), for which we can prove performance increase when using unlabeled data without needing additional assumptions. Our claim is that it is a very interesting observation that this semi-supervised version will always outperform, or at least not degrade the performance of, the supervised classifier, not that it is necessarily the best overal semi-supervised classifier.
2. While we agree the multidimensional case is even more interesting, we disagree the one-dimensional case is trivial. The proof gives insight into how and why this procedure works. In as far as this was not clear in the previous version of the manuscript, we hope we have improved the text to make this clearer.
The bigger change in the new manuscript is that we have added a proof for the multidimensional case for a slight adaptation of the procedure. The resulting theorem is a very strong result in that the procedure always gives lower loss than the supervised solution in the transductive setting.
3. This is an interesting question. In the new version of our manuscript we included the Euclidean projection in the cross-validation experiments. We hope it is clear from those results, that at least its solution is not the same as that of the original ICLS procedure. To illustrate why improvement in terms of Euclidean distance does not necessarily translate into improvement in terms of the squared loss, consider the attached illustration. The space in this illustration is the parameter space for a 2D problem. The red point indicates the supervised solution, while the green point indicates the parameters we would get if we would have the labels for all the (labeled and unlabeled) objects. The yellow point is the Euclidean projection of the supervised solution onto the constrained set (the dark region). Measured from the oracle solution, the yellow point is closer to the oracle solution in terms of Euclidean distance. In terms of the squares loss, however, indicated by the blue line, the supervised solution is closer. This example indicates why Theorem 2 does not necessarily guarantees improvement in terms of squared loss. To alleviate this problem, we added a third proof in the updated manuscript that shows an improvement in terms of squared loss, for a slightly different procedure.
4. We have attempted to improve the clarity of both proofs in our new version of the manuscript, but welcome specific comments that could further improve the clarity.
5. The main goal of this work is to show that it is possible to build a semi-supervised classifier than is never worse than its supervised counterpart. The experiments are set up to verify to what extend the proposed procedure reaches this goal. We do not feel that a comparison to other supervised and semi-supervised method, that incorporate different losses gives a clearer view of the point we would explore in the manuscript. As such we think such a comparison is beyond the scope of this paper.


Overal, we hope the addition of non-degradation of performance in the multivariate case has improved the manuscript. We think the concept of implicitly constrained semi-supervised learning and the theorems in section 4 are important because it shows that for some classifiers, semi-supervised learning without additional constraints is possible. 